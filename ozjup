#!env bash

## When run on your local machine, this script starts
## a singularity container on ozstar running jupyter, creates an 
## ssh tunnel, and starts a browser to a jupyter notebook.

OTHER_ARGUMENTS=()
oz=ozstar.swin.edu.au

SCRIPTPATH="$( cd -- "$(dirname "$0")" >/dev/null 2>&1 ; pwd -P )"/ozjup

STATUS_FILE=$HOME/.jup_status
TOKEN_FILE=$HOME/.jup_token
JOB_FILE=$HOME/.jup_jobid
# SIF_FILE=$HOME/singularity/tensorflow2-gpu-py3-r-jupyter_latest.sif
SIF_FILE=$HOME/singularity/ozjup.sif
SIF_HOME=/fred/oz012/ozjup.sif
SIF_URL=https://swift.rc.nectar.org.au/v1/AUTH_3a1bdd754ad742cba1ae637bd17e0a6a/ozjup/ozjup.sif
IMAGENAME=library://ajgreen/default/tensorflow2-gpu-py3-r-jupyter:latest
RUN_ON_NODE=
WORK_DIR="$WORK_DIR"
USERNAME="$OZSTAR_USERNAME"
PORT=9999
MEM=10
HOURS=4
GPU=yes
TOKEN_CHECK=

printhelp() {
    echo "Usage: Run on local machine; default action is to start jupyter container on a head node. 
    ./ozjup [-u username] [-n] [-m memory] [-h hours] command

Where <command> is one of:
start: Start notebook and connect.
check: Check if running and if so where
kill: Stop running instance
token: Run jupyter notebook list to view the connection token
help: Print this help and exit

With optional flags:
-u, --user: OzSTAR username (If left out, will work it out automatically, can be set with OZSTAR_USERNAME environment variable.)
-n, --node: Run on a dedicated node using a slurm job
-m, --memory: Memory required in GB (with -n only)
-h, --hours: Hours in walltime to request (with -n only)
-ng, --no-gpu: Don't ask for a GPU (with -n only)

## Examples
./ozjup -u username start # run jupyter on head node and start SSH tunnel.
./ozjup -u username -n -m 10 -h 2 start # run jupyter on job node with 10G for 2 hours, wait for job to start, then start SSH tunnel.
./ozjup check # check if it's running
./ozjup kill # kill container if running
"
}

waitjob() {
    echo Waiting for job to start...
    while [[ ! -e $STATUS_FILE ]]; do
        sleep 1
    done
    echo "Job started - firing up notebook now."
    sleep 5
}

killjob() {
    if [[ ! -e "$STATUS_FILE" ]]; then
        echo Nothing to kill.
    # elif [[ -e $JOB_FILE ]]; then
        # jobid=$(cat $JOB_FILE)
        # scancel $jobid
        # echo "Job $jobid Killed."
        # rm $JOB_FILE
        # rm $STATUS_FILE
    else
        jobhost=$(cat $STATUS_FILE)
        if [[ "$(hostname)" != "$jobhost" ]]; then
            # ssh $jobhost "bash ozjup -k"
            ssh ${jobhost} -q -t "exec bash -l ozjup -k"
        else
            running=isrunning
            if [[ "0" != running ]]; then
                singularity instance stop ozjup
            fi
            rm $STATUS_FILE
        fi
    fi
}

isrunning() {
    running=$(singularity instance list|grep ozjup)
    if [[ -n "$running" ]]; then
        echo 1
    else
        echo 0
    fi
}


isrunningold() {
    if [[ -n $(ps ux | grep 'Singularity runtime') ]]; then
        ps ux | grep 'Singularity runtime' | awk '{print $2}'
    else
        echo 0
    fi
}

runjup() {
    checksif
    workdir=$1
    singularity instance start --nv -B /apps/skylake/software/CUDA/10.1.243/lib64:/usr/local/cuda/lib64 -B "$workdir":/work $HOME/singularity/ozjup.sif ozjup
    echo $(hostname) > $STATUS_FILE
}

checkstatus() {
    localhost=$1
    if [[ -n "$1" ]]; then
        status=$(cat $STATUS_FILE)
    else
        # status=$(ssh $ozu "cat $STATUS_FILE 2>/dev/null")
        status=$(ssh $ozu "cat .jup_status 2>/dev/null")
    fi
    if [[ -n "$status" ]]; then
        echo $status
    fi
}

gettoken() {
    tokcommand="singularity exec instance://ozjup jupyter notebook list"
    jobhost=$(cat $STATUS_FILE)
    if [[ "$(hostname)" != "$jobhost" ]]; then
        result=$(ssh ${jobhost} -q -t "exec bash -l ozjup token")
    else
        result=$(singularity exec instance://ozjup jupyter notebook list|grep localhost)
    fi
    echo $result
}


sshtunnel() {
    NODENAME=$1

    echo "Starting SSH tunnel to $NODENAME..."
    # set -m
    # echo "Now connect to http://localhost:$PORT"
    token=$(ssh ${ozu} "exec bash -l ozjup token")
    echo $token
    ssh -o "StrictHostKeyChecking no" -N -L  $PORT:localhost:$PORT -J ${ozu} ${USERNAME}@${NODENAME} 
    # echo $OPENCMD http://localhost:${PORT}/ &
    # fg
}

checksif() {
    if [ ! -e $SIF_FILE ]
    then
        echo "Fetching image: this will happen only once"
        mkdir -p $HOME/singularity
        cd $HOME/singularity
        if [[ -e "$SIF_HOME" ]]; then
            ln -s $SIF_HOME ozjup.sif
        else
            wget --quiet $SIF_URL
        fi
        # singularity pull $IMAGENAME
    # else
        # echo "Image present."
    fi
}

makebatch() {
    MEM=$1
    HOURS=$2
    GPU=$3
    gpuline=""
    if [[ -n "$GPU" ]]; then
        gpuline="#SBATCH --gres=gpu"
    fi
    echo "#!/bin/bash
#SBATCH --job-name=ozjup
#SBATCH --output=$HOME/ozjup.log
#SBATCH --cpus-per-task=1
#SBATCH --time=${HOURS}:00:00
#SBATCH --mem=${MEM}G
$gpuline

module load singularity/latest
cd $HOME"'
echo $(hostname) > '"$STATUS_FILE

singularity instance start --nv -B /apps/skylake/software/CUDA/10.1.243/lib64:/usr/local/cuda/lib64 -B "$WORK_DIR":/work $HOME/singularity/ozjup.sif ozjup


jobup=1"'
while [[ "1" == "$jobup" ]]; do
    sleep 10
    running=$(singularity instance list|grep ozjup)
    if [[ -z "$running" ]]; then
        jobup=0
    fi
done

' > $HOME/runjup.sh 
    jobid=$(sbatch $HOME/runjup.sh|awk '{print $4'})
    echo $jobid > $JOB_FILE
}

allargs=$@
for arg in "$@"
do
    case $arg in
        help)
        printhelp
        exit
        shift
        ;;
        -s|start)
        START_JOB=1
        shift
        ;;
        -k|kill)
        KILL_JOB=1
        shift
        ;;
        -c|check)
        CHECK_JOB=1
        shift
        ;;
        -n|--node)
        RUN_ON_NODE=1
        shift 
        ;;
        token)
        TOKEN_CHECK=1
        shift
        ;;
        -ng|--no-gpu)
        GPU=
        shift
        ;;
        -c=*|--cache=*)
        CACHE_DIRECTORY="${arg#*=}"
        shift # Remove --cache= from processing
        ;;
        -u|--user)
        USERNAME="$2"
        shift
        # shift
        ;;
        -w|--work)
        WORK_DIR="$2"
        shift
        # shift
        ;;
        -m|--memory)
        MEM="$2"
        shift
        # shift
        ;;
        -h|--hours)
        HOURS="$2"
        shift
        # shift
        ;;
        *)
        OTHER_ARGUMENTS+=("$1")
        shift # Remove generic argument from processing
        ;;
    esac
done
# echo "Running script with these args:" $allargs





environment=home

if [ "1" -eq $(grep -i centos /etc/redhat-release 2>/dev/null |wc -l) ]
then
    if [ -n "$(hostname | grep farnarkle)" ]
    then
        environment=head
    else
        environment=node
    fi
    USERNAME=$USER
else
    if [[ -z "$USERNAME" ]]; then
        USERNAME=$(ssh $oz 'echo $USER')
    fi

    if [[ -n "$USERNAME" ]]; then
        USERNAME="$USERNAME"@
    fi
fi

ozu=${USERNAME}$oz
# echo Running on $(hostname) as user $USERNAME Node=$RUN_ON_NODE env=$environment workdir=${WORK_DIR}

if [ "$environment" = "home" ]
then
    if [[ -z "${TOKEN_CHECK}${START_JOB}${KILL_JOB}${CHECK_JOB}" ]]; then
        printhelp
        exit
    fi
    # scp -q $(realpath $0) ${ozu}:.
    scp -q $SCRIPTPATH ${ozu}:.
    if [[ -n "$CHECK_JOB" ]]; then
        status=$(checkstatus)
        if [[ -n "$status" ]]; then
            echo "Running on" $status
        else
            echo "Not running."
        fi
        exit
    fi

    # Re-execute the script, but on ozstar.
    ssh ${ozu} -q -t "exec bash -l ozjup $allargs"

    if [[ -n "$KILL_JOB$TOKEN_CHECK" ]]; then
        exit
    fi

    sleep 2
    status=$(checkstatus)
    if [[ -n "$status" ]];
    then
        sshtunnel $status
        # echo "Now connect to http://localhost:$PORT"
    else
        echo 
    fi
fi

if [ "$environment" = "head" ]
then
    module load singularity/latest
    if [[ -n "$KILL_JOB" ]]; 
    then
        killjob 
        exit
    fi
    if [[ -n "$CHECK_JOB" ]]; 
    then
        checkstatus
        exit
    fi
    if [[ -n "$TOKEN_CHECK" ]]; 
    then
        gettoken 
        exit
    fi

    if [[ -n "$WORK_DIR" ]]; then
        WORK_DIR="$HOME"
    fi 

    # OK, we're running it
    rm -f $STATUS_FILE
    rm -f $JOB_FILE

    if [ -z "$RUN_ON_NODE" ]
    then
        runjup $WORK_DIR
    else
        makebatch $MEM $HOURS $GPU
        # jobid=$(makebatch $MEM $HOURS $GPU)
        waitjob
        # waitjob $jobid
        # reportback
    fi
fi

if [ "$environment" = "node" ]
then
    module load singularity/latest
    if [[ -n "$KILL_JOB" ]]; 
    then
        killjob 
        exit
    fi
    if [[ -n "$CHECK_JOB" ]]; 
    then
        checkstatus
        exit
    fi
    if [[ -n "$TOKEN_CHECK" ]]; 
    then
        gettoken 
        exit
    fi
fi
